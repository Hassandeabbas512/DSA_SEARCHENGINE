from text_processor import tokenize

# Example text to tokenize
sample_text = "Infrastructure is the backbone of development."
tokenized_text = tokenize(sample_text)

print(f"Original Text: {sample_text}")
print(f"Tokenized: {tokenized_text}")
